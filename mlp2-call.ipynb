{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LeakyReLU, BatchNormalization\n",
    "from keras import backend\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "n_units = 400\n",
    "layers = 4\n",
    "n_batch = 4096\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df = pd.read_csv('../data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>date_ndiff</th>\n",
       "      <th>treasury_rate</th>\n",
       "      <th>closing_price</th>\n",
       "      <th>sigma_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334.0</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.57</td>\n",
       "      <td>3</td>\n",
       "      <td>15.146374</td>\n",
       "      <td>333.84</td>\n",
       "      <td>0.3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3</td>\n",
       "      <td>15.146374</td>\n",
       "      <td>333.84</td>\n",
       "      <td>0.3647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>336.0</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3</td>\n",
       "      <td>15.146374</td>\n",
       "      <td>333.84</td>\n",
       "      <td>0.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3</td>\n",
       "      <td>15.146374</td>\n",
       "      <td>333.84</td>\n",
       "      <td>0.3358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>338.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3</td>\n",
       "      <td>15.146374</td>\n",
       "      <td>333.84</td>\n",
       "      <td>0.3238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   strike_price  best_bid  best_offer  date_ndiff  treasury_rate  \\\n",
       "0         334.0      4.50        4.57           3      15.146374   \n",
       "1         335.0      3.83        3.90           3      15.146374   \n",
       "2         336.0      3.24        3.28           3      15.146374   \n",
       "3         337.0      2.68        2.72           3      15.146374   \n",
       "4         338.0      2.19        2.22           3      15.146374   \n",
       "\n",
       "   closing_price  sigma_20  \n",
       "0         333.84    0.3812  \n",
       "1         333.84    0.3647  \n",
       "2         333.84    0.3500  \n",
       "3         333.84    0.3358  \n",
       "4         333.84    0.3238  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_X_train, call_X_test, call_y_train, call_y_test = train_test_split(call_df.drop(['best_bid', 'best_offer'], axis=1),\n",
    "                                                                        call_df[['best_bid', 'best_offer']],\n",
    "                                                                        test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(n_units, input_dim=call_X_train.shape[1]))\n",
    "model.add(LeakyReLU())\n",
    "\n",
    "for _ in range(layers - 1):\n",
    "    model.add(Dense(n_units))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "\n",
    "model.add(Dense(2, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 400)               2400      \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 400)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 400)              1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 400)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 400)              1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 400)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 400)               160400    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 400)              1600      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 400)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 802       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 489,202\n",
      "Trainable params: 486,802\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 4s 188ms/step - loss: 489.6070 - val_loss: 580.1790\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 307.9321 - val_loss: 190.4507\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 2s 166ms/step - loss: 211.5641 - val_loss: 576.9182\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 2s 142ms/step - loss: 143.4722 - val_loss: 1053.7781\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 94.6743 - val_loss: 535.3347\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 61.2614 - val_loss: 186.8153\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 40.2256 - val_loss: 134.8028\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 28.4874 - val_loss: 147.1667\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 19.7036 - val_loss: 110.6463\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 2s 151ms/step - loss: 15.9216 - val_loss: 126.2581\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 2s 142ms/step - loss: 12.7982 - val_loss: 96.6683\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 11.5569 - val_loss: 27.7436\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 9.7753 - val_loss: 21.3932\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 9.2677 - val_loss: 14.6759\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 2s 171ms/step - loss: 8.5312 - val_loss: 13.8513\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 6.8853 - val_loss: 16.8858\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 6.5745 - val_loss: 29.8878\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 8.5919 - val_loss: 12.9625\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 6.5652 - val_loss: 14.6304\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 5.2910 - val_loss: 21.5557\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 5.1988 - val_loss: 27.8218\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 5.4270 - val_loss: 144.2979\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 4.9597 - val_loss: 96.1481\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 4.7411 - val_loss: 30.1932\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 4.4427 - val_loss: 39.0932\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 5.1902 - val_loss: 36.8161\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 4.7985 - val_loss: 6.9968\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 4.2882 - val_loss: 19.2738\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 4.0424 - val_loss: 20.8029\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 4.1479 - val_loss: 35.7441\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 3.7343 - val_loss: 22.5331\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 4.5422 - val_loss: 26.4284\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 3.7892 - val_loss: 9.7747\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 4.0370 - val_loss: 13.5860\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 4.1823 - val_loss: 23.6407\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 4.0257 - val_loss: 16.1111\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 3.9069 - val_loss: 19.5587\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 3.2431 - val_loss: 3.2058\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 3.1448 - val_loss: 4.7169\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 3.0012 - val_loss: 9.0471\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 4.0099 - val_loss: 26.4017\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 4.3852 - val_loss: 56.6487\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 3.4813 - val_loss: 20.0475\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 3.3618 - val_loss: 7.9368\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 3.1258 - val_loss: 11.2310\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 3.9959 - val_loss: 4.9368\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 4.0134 - val_loss: 12.5576\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 3.2396 - val_loss: 11.4259\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 3.8393 - val_loss: 4.8967\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 3.2771 - val_loss: 27.0264\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=n_epochs, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mlp2-call30.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "call_y_pred30 = model.predict(call_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equilibrium mse 29.32860403585211\n",
      "spread mse 0.22965403636740409\n"
     ]
    }
   ],
   "source": [
    "print('equilibrium mse', np.mean(np.square(np.mean(call_y_test.values, axis=1) - np.mean(call_y_pred30, axis=1))))\n",
    "print('spread mse', np.mean(np.square(np.diff(call_y_test.values, axis=1) - np.diff(call_y_pred30, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 3s 146ms/step - loss: 3.1918 - val_loss: 16.9369\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 2.7751 - val_loss: 18.7113\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 2.7199 - val_loss: 4.0577\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 2.9979 - val_loss: 17.1505\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 2.8396 - val_loss: 5.1376\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 2.6223 - val_loss: 4.5321\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 2.5063 - val_loss: 6.6928\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 2.4407 - val_loss: 1.9820\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 2.5712 - val_loss: 2.1072\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 2.4681 - val_loss: 7.0342\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 2.3514 - val_loss: 4.3654\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 2.5716 - val_loss: 3.2530\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 2.4595 - val_loss: 2.6680\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 2.3452 - val_loss: 2.3715\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 2s 152ms/step - loss: 2.4692 - val_loss: 3.8178\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 2.3726 - val_loss: 2.2326\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 2.3502 - val_loss: 11.0729\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 2.2830 - val_loss: 7.0458\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 2.3404 - val_loss: 11.5392\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 2s 148ms/step - loss: 2.4659 - val_loss: 2.7604\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 2s 161ms/step - loss: 2.6006 - val_loss: 3.2444\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 2s 144ms/step - loss: 2.2465 - val_loss: 3.0641\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 2s 147ms/step - loss: 2.2252 - val_loss: 3.9300\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 2.3136 - val_loss: 5.6736\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 2s 146ms/step - loss: 2.1869 - val_loss: 3.9237\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 2.2790 - val_loss: 2.5901\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 2.2634 - val_loss: 14.3260\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 2.4637 - val_loss: 9.3396\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 2.5208 - val_loss: 5.1956\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 2.2991 - val_loss: 6.6411\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 2.0947 - val_loss: 4.2839\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 2.2248 - val_loss: 6.5364\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 2.5241 - val_loss: 3.7525\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 2s 164ms/step - loss: 2.4247 - val_loss: 12.3281\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 2.3502 - val_loss: 23.4386\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 2s 174ms/step - loss: 2.2008 - val_loss: 21.3222\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 2s 175ms/step - loss: 2.4382 - val_loss: 4.5768\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 2s 162ms/step - loss: 2.4444 - val_loss: 4.1681\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 2.5897 - val_loss: 2.0504\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 2s 176ms/step - loss: 2.7472 - val_loss: 7.0587\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 2s 181ms/step - loss: 2.6783 - val_loss: 6.6325\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 2.3302 - val_loss: 6.8882\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 2s 165ms/step - loss: 2.1682 - val_loss: 6.4645\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 2s 173ms/step - loss: 2.4121 - val_loss: 2.7943\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 2s 170ms/step - loss: 2.0827 - val_loss: 6.6186\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 2s 172ms/step - loss: 2.3320 - val_loss: 9.3120\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 2s 163ms/step - loss: 2.1969 - val_loss: 3.3820\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 2s 195ms/step - loss: 1.9866 - val_loss: 2.1282\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 2.2105 - val_loss: 7.0873\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 2.2156 - val_loss: 2.9636\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(1e-4))\n",
    "history = model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=n_epochs, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mlp2-call40.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 3ms/step\n",
      "equilibrium mse 3.0163733005580244\n",
      "spread mse 0.17447371990407556\n"
     ]
    }
   ],
   "source": [
    "call_y_pred40 = model.predict(call_X_test)\n",
    "print('equilibrium mse', np.mean(np.square(np.mean(call_y_test.values, axis=1) - np.mean(call_y_pred40, axis=1))))\n",
    "print('spread mse', np.mean(np.square(np.diff(call_y_test.values, axis=1) - np.diff(call_y_pred40, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 5s 223ms/step - loss: 2.2818 - val_loss: 7.0725\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 2s 220ms/step - loss: 2.1132 - val_loss: 6.9057\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 1.9540 - val_loss: 6.3352\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 2s 197ms/step - loss: 1.9409 - val_loss: 4.2723\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 3s 283ms/step - loss: 1.8800 - val_loss: 4.5141\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 2s 171ms/step - loss: 1.9837 - val_loss: 4.8216\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 2.1604 - val_loss: 3.5536\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 169ms/step - loss: 2.0528 - val_loss: 5.2982\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 145ms/step - loss: 2.0931 - val_loss: 5.3414\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 208ms/step - loss: 1.9774 - val_loss: 4.0310\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(1e-5))\n",
    "history = model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=10, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 1ms/step\n",
      "equilibrium mse 3.929644410975308\n",
      "spread mse 0.17185924066445898\n"
     ]
    }
   ],
   "source": [
    "model.save('mlp2-call50.h5')\n",
    "call_y_pred50 = model.predict(call_X_test)\n",
    "print('equilibrium mse', np.mean(np.square(np.mean(call_y_test.values, axis=1) - np.mean(call_y_pred50, axis=1))))\n",
    "print('spread mse', np.mean(np.square(np.diff(call_y_test.values, axis=1) - np.diff(call_y_pred50, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 3s 183ms/step - loss: 1.9437 - val_loss: 3.5873\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 1.9402 - val_loss: 3.2885\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 2s 142ms/step - loss: 2.3196 - val_loss: 3.0457\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 1.9715 - val_loss: 2.8358\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 2.0326 - val_loss: 2.5726\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 1.9392 - val_loss: 2.2569\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 2.1521 - val_loss: 2.1403\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 1.8301 - val_loss: 2.0437\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 1.9234 - val_loss: 1.9797\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 2s 141ms/step - loss: 2.0134 - val_loss: 1.9081\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=Adam(1e-6))\n",
    "history = model.fit(call_X_train, call_y_train, \n",
    "                    batch_size=n_batch, epochs=10, \n",
    "                    validation_split = 0.01,\n",
    "                    callbacks=[TensorBoard()],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n",
      "equilibrium mse 2.035315241687155\n",
      "spread mse 0.1716649090513774\n"
     ]
    }
   ],
   "source": [
    "model.save('mlp2-call60.h5')\n",
    "call_y_pred60 = model.predict(call_X_test)\n",
    "print('equilibrium mse', np.mean(np.square(np.mean(call_y_test.values, axis=1) - np.mean(call_y_pred60, axis=1))))\n",
    "print('spread mse', np.mean(np.square(np.diff(call_y_test.values, axis=1) - np.diff(call_y_pred60, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(call_y_pred60, np.array(call_y_test),'o')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
